# å¿«é€Ÿå¯åŠ¨æŒ‡å—ï¼ˆRTX 5080 + Docker Desktopï¼‰

## ğŸš€ ä¸€é”®å¯åŠ¨ï¼ˆæ¨èï¼‰

### æ­¥éª¤ 1: éªŒè¯ Docker GPU æ”¯æŒ

```bash
docker run --rm --gpus all nvidia/cuda:12.1.0-base-ubuntu22.04 nvidia-smi
```

å¦‚æœèƒ½çœ‹åˆ° GPU ä¿¡æ¯ï¼Œè¯´æ˜é…ç½®æ­£ç¡® âœ…

### æ­¥éª¤ 2: å¯åŠ¨æœåŠ¡

```bash
cd openai-translator-chatglm
docker-compose up -d --build
```

### æ­¥éª¤ 3: æŸ¥çœ‹æ—¥å¿—

```bash
docker-compose logs -f
```

ç­‰å¾…çœ‹åˆ° "Running on local URL: http://0.0.0.0:7860" è¡¨ç¤ºå¯åŠ¨æˆåŠŸ âœ…

### æ­¥éª¤ 4: è®¿é—®åº”ç”¨

æ‰“å¼€æµè§ˆå™¨è®¿é—®ï¼š**http://localhost:7860**

## ğŸ“‹ å®Œæ•´æµç¨‹

### é¦–æ¬¡è¿è¡Œ

1. **æ„å»ºé•œåƒ**ï¼ˆé¦–æ¬¡éœ€è¦ï¼Œåç»­å¯è·³è¿‡ï¼‰
   ```bash
   docker-compose build
   ```

2. **å¯åŠ¨æœåŠ¡**
   ```bash
   docker-compose up -d
   ```

3. **ç­‰å¾…æ¨¡å‹ä¸‹è½½**ï¼ˆé¦–æ¬¡è¿è¡Œï¼‰
   - æŸ¥çœ‹æ—¥å¿—ï¼š`docker-compose logs -f`
   - æ¨¡å‹çº¦ 12GBï¼Œä¸‹è½½éœ€è¦ä¸€äº›æ—¶é—´
   - ä¸‹è½½å®Œæˆåä¼šè‡ªåŠ¨åŠ è½½æ¨¡å‹

4. **è®¿é—®ç•Œé¢**
   - æµè§ˆå™¨æ‰“å¼€ï¼šhttp://localhost:7860
   - ç•Œé¢åŠ è½½åå³å¯ä½¿ç”¨

### æ—¥å¸¸ä½¿ç”¨

```bash
# å¯åŠ¨
docker-compose up -d

# åœæ­¢
docker-compose down

# æŸ¥çœ‹çŠ¶æ€
docker-compose ps

# æŸ¥çœ‹æ—¥å¿—
docker-compose logs -f
```

## ğŸ”§ é…ç½®è°ƒæ•´

### ä¿®æ”¹ç¯å¢ƒå˜é‡

ç¼–è¾‘ `docker-compose.yml` æˆ–åˆ›å»º `.env` æ–‡ä»¶ï¼š

```env
MODEL_PATH=THUDM/chatglm2-6b
DEVICE=cuda
MAX_LENGTH=2048
TOP_P=0.7
TEMPERATURE=0.95
```

ç„¶åé‡å¯ï¼š

```bash
docker-compose down
docker-compose up -d
```

## ğŸ› æ•…éšœæ’é™¤

### é—®é¢˜ 1: GPU ä¸å¯ç”¨

**æ£€æŸ¥**ï¼š
```bash
docker exec openai-translator-chatglm nvidia-smi
```

**è§£å†³**ï¼š
- ç¡®ä¿ Docker Desktop å·²å¯ç”¨ GPU æ”¯æŒ
- æ£€æŸ¥ NVIDIA é©±åŠ¨æ˜¯å¦æœ€æ–°
- é‡å¯ Docker Desktop

### é—®é¢˜ 2: ç«¯å£è¢«å ç”¨

**è§£å†³**ï¼šä¿®æ”¹ `docker-compose.yml` ä¸­çš„ç«¯å£æ˜ å°„ï¼š
```yaml
ports:
  - "7861:7860"  # æ”¹ä¸ºå…¶ä»–ç«¯å£
```

### é—®é¢˜ 3: æ¨¡å‹ä¸‹è½½å¤±è´¥

**è§£å†³**ï¼š
- æ£€æŸ¥ç½‘ç»œè¿æ¥
- ä½¿ç”¨ HuggingFace é•œåƒ
- æ‰‹åŠ¨ä¸‹è½½æ¨¡å‹åˆ° `./models` ç›®å½•

### é—®é¢˜ 4: å†…å­˜ä¸è¶³

**è§£å†³**ï¼š
- å¢åŠ  Docker Desktop å†…å­˜åˆ†é…
- ä½¿ç”¨é‡åŒ–æ¨¡å‹
- å‡å°‘ `MAX_LENGTH` å‚æ•°

## ğŸ“Š æ€§èƒ½ç›‘æ§

### æŸ¥çœ‹ GPU ä½¿ç”¨æƒ…å†µ

```bash
docker exec openai-translator-chatglm nvidia-smi
```

### æŸ¥çœ‹å®¹å™¨èµ„æºä½¿ç”¨

```bash
docker stats openai-translator-chatglm
```

### æŸ¥çœ‹åº”ç”¨æ—¥å¿—

```bash
docker-compose logs -f translator
```

## ğŸ¯ RTX 5080 ä¼˜åŒ–å»ºè®®

RTX 5080 æœ‰å……è¶³çš„æ˜¾å­˜ï¼Œå¯ä»¥ï¼š

1. **ä½¿ç”¨å®Œæ•´æ¨¡å‹**ï¼ˆæ— éœ€é‡åŒ–ï¼‰
2. **å¢åŠ  MAX_LENGTH**ï¼ˆæ”¯æŒæ›´é•¿æ–‡æœ¬ï¼‰
3. **æ‰¹é‡å¤„ç†**ï¼ˆåŒæ—¶å¤„ç†å¤šä¸ªä»»åŠ¡ï¼‰

åœ¨ `docker-compose.yml` ä¸­è°ƒæ•´ï¼š

```yaml
environment:
  - MAX_LENGTH=4096  # å¢åŠ åˆ° 4096
  - DEVICE=cuda
```

## âœ… éªŒè¯æ¸…å•

å¯åŠ¨åæ£€æŸ¥ï¼š

- [ ] å®¹å™¨è¿è¡Œæ­£å¸¸ï¼š`docker-compose ps`
- [ ] GPU å¯ç”¨ï¼š`docker exec openai-translator-chatglm nvidia-smi`
- [ ] ç•Œé¢å¯è®¿é—®ï¼šhttp://localhost:7860
- [ ] å¯ä»¥ä¸Šä¼  PDF
- [ ] ç¿»è¯‘åŠŸèƒ½æ­£å¸¸

## ğŸ“š æ›´å¤šä¿¡æ¯

- è¯¦ç»† Docker æŒ‡å—ï¼šæŸ¥çœ‹ [DOCKER_GUIDE.md](DOCKER_GUIDE.md)
- å®Œæ•´æ–‡æ¡£ï¼šæŸ¥çœ‹ [README.md](README.md)
- é¡¹ç›®æ€»ç»“ï¼šæŸ¥çœ‹ [PROJECT_SUMMARY.md](PROJECT_SUMMARY.md)

---

**ç¥ä½¿ç”¨æ„‰å¿«ï¼** ğŸ‰

